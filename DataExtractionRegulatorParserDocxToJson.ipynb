{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/tubagokhan/ADGM/blob/main/RegulatorParserToJson.ipynb",
      "authorship_tag": "ABX9TyMUsJbRup1kP03JsqA9i0AL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tubagokhan/RegNLPDataset/blob/main/DataExtractionRegulatorParserDocxToJson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiyZqLA-3sUS",
        "outputId": "38f9069a-3685-456e-8222-8b081b7f55c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4C7wJbF39tR",
        "outputId": "9cdeee1e-bf1a-4ec4-838b-90d59217b08b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/239.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgk8q8Qs3gTG",
        "outputId": "a93cdc74-d006-4fd1-cba2-4c1df1b6dcad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extracted from /content/COBS_VER15.150823.docx and saved to JSON file: /content/COBS_VER15.150823.json\n"
          ]
        }
      ],
      "source": [
        "from docx import Document\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def extract_data_from_docx(docx_path):\n",
        "    # Load the DOCX file\n",
        "    doc = Document(docx_path)\n",
        "\n",
        "    # Initialize variables\n",
        "    section_id = 0\n",
        "    subsection_id = 0\n",
        "    context_id = 0\n",
        "    current_section = \"\"\n",
        "    current_subsection = \"\"\n",
        "    current_context = \"\"\n",
        "    data_structure = []\n",
        "    context_level = 0\n",
        "    heading_encountered = False  # Variable to track if a heading has been encountered\n",
        "\n",
        "    # Process the document\n",
        "    for para in doc.paragraphs:\n",
        "        if para.style.name.startswith('Heading'):\n",
        "            heading_level = int(para.style.name.split(' ')[-1])\n",
        "            heading_encountered = True  # Set flag to True once a heading is encountered\n",
        "\n",
        "            if heading_level <= context_level:\n",
        "                # Append the last context before starting a new one\n",
        "                data_structure.append({\n",
        "                    \"SectionID\": str(section_id),\n",
        "                    \"SectionHeader\": current_section,\n",
        "                    \"SubSectionID\": f\"{section_id}.{subsection_id}\",\n",
        "                    \"SubSectionHeader\": current_subsection,\n",
        "                    \"ContextID\": f\"{section_id}.{subsection_id}.{context_id}\",\n",
        "                    \"Context\": current_context.strip()\n",
        "                })\n",
        "                current_context = \"\"\n",
        "\n",
        "            if 'Heading 1' in para.style.name:\n",
        "                section_id += 1\n",
        "                subsection_id = 0\n",
        "                context_id = 0\n",
        "                current_section = para.text.strip()\n",
        "                context_level = 1\n",
        "\n",
        "            elif 'Heading 2' in para.style.name:\n",
        "                subsection_id += 1\n",
        "                context_id = 0\n",
        "                current_subsection = para.text.strip()\n",
        "                context_level = 2\n",
        "\n",
        "            elif 'Heading 3' in para.style.name:\n",
        "                context_id += 1\n",
        "                context_level = 3\n",
        "                current_context += para.text + \" \"\n",
        "\n",
        "            elif para.style.name != \"Heading 1\" and para.style.name != \"Heading 2\" and para.style.name != \"Heading 3\":\n",
        "                current_context += para.text + \" \"\n",
        "\n",
        "        elif heading_encountered and (para.style.name in [\"UK11 Block 0.5\", \"UK11 Block 1.0\", \"Normal\", \"List Paragraph\"] or context_level >= 3):\n",
        "            # Accumulate text for the current context\n",
        "            current_context += para.text + \" \"\n",
        "\n",
        "    # Add the last context if it was not added\n",
        "    if current_context:\n",
        "        data_structure.append({\n",
        "            \"SectionID\": str(section_id),\n",
        "            \"SectionHeader\": current_section,\n",
        "            \"SubSectionID\": f\"{section_id}.{subsection_id}\",\n",
        "            \"SubSectionHeader\": current_subsection,\n",
        "            \"ContextID\": f\"{section_id}.{subsection_id}.{context_id}\",\n",
        "            \"Context\": current_context.strip()\n",
        "        })\n",
        "\n",
        "    return data_structure\n",
        "\n",
        "def process_all_docx_in_folder(folder_path):\n",
        "    for docx_file in glob.glob(os.path.join(folder_path, '*.docx')):\n",
        "        extracted_data = extract_data_from_docx(docx_file)\n",
        "        json_path = docx_file.rsplit('.', 1)[0] + '.json'\n",
        "        with open(json_path, 'w') as json_file:\n",
        "            json.dump(extracted_data, json_file, indent=4)\n",
        "        print(f\"Data extracted from {docx_file} and saved to JSON file: {json_path}\")\n",
        "\n",
        "# Specify the folder containing the DOCX files\n",
        "folder_path = '/content'  # Replace with your folder path\n",
        "process_all_docx_in_folder(folder_path)\n"
      ]
    }
  ]
}